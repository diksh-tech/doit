from fastapi import FastAPI, Query
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from fastmcp import Client
from fastmcp.client.transports import StreamableHttpTransport
from openai import AzureOpenAI
from ag_ui.encoder import EventEncoder
from ag_ui.core import (
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallResultEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    EventType,
)
import asyncio
import json
import re
import os
import traceback
import sys
import httpx
from dotenv import load_dotenv
import uvicorn
from toon import encode
from redis import Redis
from redis_entraid.cred_provider import create_from_service_principal
load_dotenv()
import ssl
import logging
from pymongo import MongoClient, errors
from variables import weather_schema, toon_payload, msg 
from mongoDB import insert_weather_chat


app = FastAPI()
 
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
 
# MCP Server configuration - aligned with your test script
MCP_BASE_URL = os.getenv("MCP_BASE_URL", "http://127.0.0.1:8000")
MCP_TOKEN_URL = f"{MCP_BASE_URL}/auth/token"
MCP_SERVER_URL = f"{MCP_BASE_URL}/mcp"
 
# Azure OpenAI configuration
llm = AzureOpenAI(
    api_key=os.getenv("subscription_key"),
    api_version=os.getenv("api_version"),
    azure_endpoint=os.getenv("endpoint"),
)
# ----------------- Redis CONFIG -----------------
# : In production, keep these in .env, yaha concept test ke liye assume env se aa rahe
# ...existing code...
# ----------------- Redis CONFIG -----------------
REDIS_HOST = "occh-uamr01.centralindia.redis.azure.net"
REDIS_PORT = 10000
 
REDIS_CLIENT_ID = os.getenv("REDIS_CLIENT_ID") # = CLIENT_ID
REDIS_CLIENT_SECRET = os.getenv("REDIS_CLIENT_SECRET") # = CLIENT_SECRET
REDIS_TENANT_ID = os.getenv("REDIS_TENANT_ID") # = TENANT_ID
 
# create credential provider only (do not instantiate Redis yet)
try:
    redis_credential_provider = create_from_service_principal(
        REDIS_CLIENT_ID,
        REDIS_CLIENT_SECRET,
        REDIS_TENANT_ID,
    )
except Exception as e:
    logger.error("Failed to create redis credential provider: %s", e)
    redis_credential_provider = None
 
# DEV: create SSL flags that disable verification (ONLY FOR DEV)
_dev_disable_ssl_verify = os.getenv("DISABLE_REDIS_SSL_VERIFY", "1") == "1"
if _dev_disable_ssl_verify:
    logger.warning("Redis SSL verification DISABLED (development)")
 
redis_client = None
 
try:
    if redis_credential_provider:
        # NOTE: redis-py versions differ in accepted SSL params.
        # Many versions do NOT accept ssl_context in Redis(...), so use ssl_cert_reqs and ssl_check_hostname.
        redis_client = Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            ssl=True,
            credential_provider=redis_credential_provider,
            decode_responses=True,
            socket_timeout=5,            # read timeout
            socket_connect_timeout=5,    # connect timeout
            ssl_cert_reqs=None if _dev_disable_ssl_verify else "required",
            ssl_check_hostname=False if _dev_disable_ssl_verify else True,
        )
        # quick non-fatal ping to surface connectivity issues early
        try:
            ok = redis_client.ping()
            logger.info("Redis ping -> %s", ok)
        except Exception as e:
            logger.warning("Redis ping failed (will continue): %s", e)
    else:
        redis_client = None
except TypeError as te:
    logger.error("Redis client init TypeError (unsupported arg): %s", te)
    redis_client = None
except Exception as e:
    logger.error("Failed to create redis_client: %s", e)
    redis_client = None


NAMESPACE = "non-prod"
PROJECT = "occhub"
MODULE = "weather_mcp"

# Concept test: single dummy session (fallback)
DUMMY_SESSION_ID = "test-session-1"

HISTORY_TTL_SECONDS = 60 * 60 * 24  # 1 day
MAX_HISTORY_MESSAGES = 20  # last 20 messages (user+assistant)


def _sanitize_id(part: str) -> str:
    """
    Sanitize user/session identifiers for safe Redis keys.
    Keeps alphanumeric, "-" and "_", replaces everything else with "_".
    """
    if not part:
        return "anon"
    return "".join(ch if ch.isalnum() or ch in ("-", "_") else "_" for ch in str(part))


def make_history_key(user_id: str, session_id: str) -> str:
    """
    <namespace>:<project>:<module>:history:<user_id>:<session_id>
    """
    uid = _sanitize_id(user_id)
    sid = _sanitize_id(session_id)
    return f"{NAMESPACE}:{PROJECT}:{MODULE}:history:{uid}:{sid}"


# ...existing code...


def append_turn_to_history(user_id: str, session_id: str, user_msg: str, assistant_msg: str) -> None:
    """
    Store one full turn (user + assistant) in Redis List for a given user + session.
    Defensive: it returns immediately if Redis is unavailable or any operation fails.
    """
    if not redis_client:
        logger.debug("append_turn_to_history: redis_client is not available, skipping")
        return

    key = make_history_key(user_id, session_id)
    user_entry = json.dumps({"role": "user", "content": user_msg}, ensure_ascii=False)
    assistant_entry = json.dumps({"role": "assistant", "content": assistant_msg}, ensure_ascii=False)

    try:
        pipe = redis_client.pipeline()
        pipe.rpush(key, user_entry, assistant_entry)
        pipe.expire(key, HISTORY_TTL_SECONDS)
        pipe.execute()
    except Exception as e:
        logger.warning("append_turn_to_history failed for key=%s: %s", key, e)


def load_history_messages(user_id: str, session_id: str, max_messages: int = MAX_HISTORY_MESSAGES):
    """
    Load last N messages from Redis for a given user + session and return as list of dicts.
    Defensive: returns empty list if Redis is unavailable or on error.
    """
    if not redis_client:
        logger.debug("load_history_messages: redis_client is not available")
        return []

    key = make_history_key(user_id, session_id)
    try:
        length = redis_client.llen(key)
    except Exception as e:
        logger.warning("Redis llen failed for key=%s: %s", key, e)
        return []

    if not length:
        return []

    start = max(0, length - max_messages)
    try:
        raw_msgs = redis_client.lrange(key, start, -1)
    except Exception as e:
        logger.warning("Redis lrange failed for key=%s: %s", key, e)
        return []

    messages = []
    for raw in raw_msgs:
        try:
            messages.append(json.loads(raw))
        except Exception:
            continue
    return messages

# ...existing code...
encoder = EventEncoder()

 
async def fetch_mcp_token() -> str:
    """Fetch authentication token for MCP server - aligned with test script."""
    try:
        async with httpx.AsyncClient(timeout=15.0) as http:
            print(f"üîê Requesting token from: {MCP_TOKEN_URL}")
            response = await http.post(MCP_TOKEN_URL)
            response.raise_for_status()
            data = response.json()
           
            if not data.get("access_token"):
                raise RuntimeError(f"Token API returned error: {data}")
           
            print(f"‚úÖ Successfully obtained MCP authentication token")
            print(f"üìä Token expires in: {data.get('expires_in', 'unknown')} seconds")
            return data["access_token"]
           
    except httpx.RequestError as e:
        print(f"‚ùå Failed to fetch MCP token - Connection error: {e}")
        # Authentication server not available - this is expected during development
        return None
    except httpx.HTTPStatusError as e:
        print(f"‚ùå Failed to fetch MCP token - HTTP {e.response.status_code}: {e.response.text}")
        return None
    except Exception as e:
        print(f"‚ùå Unexpected error fetching MCP token: {e}")
        return None
 
async def create_mcp_client():
    """Create MCP client with authentication - aligned with test script transport."""
    try:
        # Try to get authentication token first
        token = await fetch_mcp_token()
       
        if token:
            # Use HTTP transport with authentication (same as test script)
            print(f"üîê Connecting to MCP server with authentication: {MCP_SERVER_URL}")
            transport = StreamableHttpTransport(
                url=MCP_SERVER_URL,
                headers={"Authorization": f"Bearer {token}"}
            )
            return Client(transport)
        else:
            # Fall back to stdio transport for development
            print(f"üîì Authentication not available, falling back to stdio transport")
            print(f"üí° Make sure MCP server is running on {MCP_BASE_URL}")
            return Client("../weather/app.py")
           
    except Exception as e:
        print(f"‚ùå Failed to create MCP client: {e}")
        traceback.print_exc()
        # Final fallback
        print(f"üîÑ Using stdio connection as final fallback")
        return Client("../weather/app.py")
 
 
 
async def test_mcp_connection():
    """Test MCP connection using ping tool (like the test script)."""
    try:
        client = await create_mcp_client()
        async with client:
            # Test with ping tool like your test script
            result = await client.call_tool("ping")
            print(f"üèì MCP Server ping test: {result.data}")
            return True
    except Exception as e:
        print(f"‚ùå MCP connection test failed: {e}")
        return False
 
async def interact_with_server(user_prompt: str, session_id: str, user_id: str):
    """Main orchestration generator that yields AG-UI events for streaming."""
    # session_id=DUMMY_SESSION_ID
    client = None
    actual_tool_queries ={}
    graphs = None
    try:
        # Create authenticated MCP client
        client = await create_mcp_client()
       
        async with client:
            # Start the run
            yield encoder.encode(RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id="thread_1",
                run_id="run_1"
            ))
           
            # Start assistant message
            yield encoder.encode(TextMessageStartEvent(
                type=EventType.TEXT_MESSAGE_START,
                message_id="msg_1",
                role="assistant"
            ))
 
            # Discover tools from MCP server
            print(f"üîç Discovering available tools from MCP server...")
           
            tool_descriptions = await client.list_tools()
            print(f"üìã Found {len(tool_descriptions)} tools: {[t.name for t in tool_descriptions]}")
           
            openai_tools = [
                {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.inputSchema,
                    },
                }
                for tool in tool_descriptions
            ]
 
            toon = toon_payload
            schema = weather_schema          
            schema_toon = encode(schema)
 
            sys_msg =msg
 
            messages = [
                {"role": "system", "content": sys_msg},
                {"role": "system", "content": "key Value pairs of airport:\n" + toon},
                {"role": "system", "content": "Schema (JSON):\n" + schema_toon},
            ]
 
           
            # 2) Conversation history from Redis (per user + session)
            history_messages = load_history_messages(user_id, session_id)
            print("1.5")
            if history_messages:
                print(
                    f"üß† Loaded {len(history_messages)} history messages "
                    f"from Redis for user={user_id}, session={session_id}"
                )
            messages.extend(history_messages)
            # 3) Current user prompt
            messages.append(
                {
                    "role": "user",
                    "content": "The User prompt is as follows:\n" + user_prompt,
                }
            )
            # print(messages)
            
            while True:
                print(f"ü§ñ Sending request to Azure OpenAI...")
                response = llm.chat.completions.create(
                    model=os.getenv("deployment"),
                    messages=messages,
                    tool_choice="auto",
                    tools=openai_tools if openai_tools else None,
                    stream=False,
                )
 
                # print(response.usage)
 
                message = response.choices[0].message
                finish_reason = response.choices[0].finish_reason
 
                # === TOOL CALLING BRANCH ===
                if message.tool_calls:
                    print(f"üîß LLM wants to call {len(message.tool_calls)} tool(s)")
                   
                    messages.append({
                        "role": "assistant",
                        "content": message.content,
                        "tool_calls": [
                            {
                                "id": tc.id,
                                "type": "function",
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments,
                                },
                            }
                            for tc in message.tool_calls
                        ],
                    })
 
                    for tool_call in message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)
 
                        # Capture the actual tool call for MongoDB logging
                        actual_tool_queries[tool_name] = tool_args if tool_args else None

                        print(f"  ‚öôÔ∏è  Calling tool: {tool_name} with args: {tool_args}")
 
                        yield encoder.encode(
                            ToolCallStartEvent(
                                type=EventType.TOOL_CALL_START,
                                tool_call_id=tool_call.id,
                                tool_call_name=tool_name,
                            )
                        )
                       
                        yield encoder.encode(
                            ToolCallArgsEvent(
                                type=EventType.TOOL_CALL_ARGS,
                                tool_call_id=tool_call.id,
                                delta=json.dumps(tool_args),
                            )
                        )
 
                        # Call the tool with authentication (like test script)
                        try:
                            print(f"  üì° Executing authenticated tool call on MCP server...")
                            result = await client.call_tool(tool_name, tool_args)
                           
                            # Handle result data properly
                            if hasattr(result, 'data'):
                                result_data = result.data
                            else:
                                result_data = result
                           
                            if isinstance(result_data, dict):
                                result_content = result_data.get("content", str(result_data))
                            else:
                                result_content = str(result_data)
 
                            print(f"  ‚úÖ Tool result: {result_content[:200]}{'...' if len(result_content) > 200 else ''}")
                           
                        except Exception as tool_error:
                            print(f"  ‚ùå Tool call failed: {tool_error}")
                            traceback.print_exc()
                            result_content = f"Tool call failed: {str(tool_error)}"
 
                        yield encoder.encode(
                            ToolCallResultEvent(
                                type=EventType.TOOL_CALL_RESULT,
                                message_id="msg_1",
                                tool_call_id=tool_call.id,
                                content=result_content,
                                role="tool",
                            )
                        )
                        
                        if tool_name == "table_and_graph_JSON_generater":
                            cleaned = re.sub(r'^```json|```$', '', result_content, flags=re.MULTILINE)
                            result_tg = json.loads(cleaned)
                            result_tg = json.dumps(result_tg)
                            # print(result_data)
                            graphs = "data: " + result_tg + "\n\n"
                            # print(graphs)
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": "json generated",
                            })
                        else:
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": result_content,
                            })
 
                    continue
 
                # === TEXT RESPONSE BRANCH ===
                else:
                    print(f"üí¨ LLM final response (finish_reason: {finish_reason})")
                   
                    if message.content:
                        content = message.content
                        print(f"üìù Starting to stream {len(content)} characters...")
                       
                        # Stream character by character
                        for i, char in enumerate(content):
                            event_data = encoder.encode(
                                TextMessageContentEvent(
                                    type=EventType.TEXT_MESSAGE_CONTENT,
                                    message_id="msg_1",
                                    delta=char,
                                )
                            )
                            yield event_data
                           
                            # Print progress every 50 characters
                            if (i + 1) % 50 == 0:
                                print(f"  üì§ Streamed {i + 1}/{len(content)} chars", flush=True)
                           
                            # Delay for typing effect
                            await asyncio.sleep(0.02)
                       
                        print(f"  ‚úÖ Finished streaming all {len(content)} characters")
                   
                        try:
                            append_turn_to_history(user_id, session_id, user_prompt, content)
                            print(
                                f"üíæ Saved turn to Redis for user={user_id}, session={session_id}"
                            )
                        except Exception as redis_err:
                            print(f"‚ö†Ô∏è Failed to write chat history to Redis: {redis_err}")
                   
                    if graphs is not None:
                        yield graphs
 
                   
                    yield encoder.encode(
                        TextMessageEndEvent(
                            type=EventType.TEXT_MESSAGE_END,
                            message_id="msg_1"
                        )
                    )
                   
                    yield encoder.encode(
                        RunFinishedEvent(
                            type=EventType.RUN_FINISHED,
                            thread_id="thread_1",
                            run_id="run_1"
                        )
                    )
                   
                    print("‚úÖ Conversation complete!")
                    
                    try:
                        await insert_weather_chat(
                            uid=user_id,
                            session_id=session_id,
                            user_chat=user_prompt,
                            final_response=content,
                            tool_queries=actual_tool_queries if actual_tool_queries else {"no_tools": None}
                        )
                
                    except errors.PyMongoError as e:
                        print("‚ùå MongoDB Error:", e)

                    break
 
    except Exception as e:
        print(f"‚ùå Error in interact_with_server: {str(e)}")
        traceback.print_exc()
        yield encoder.encode(
            RunErrorEvent(
                type=EventType.RUN_ERROR,
                message=str(e)
            )
        )
    finally:
        if client:
            print("üîö MCP client interaction complete.")
 
 

@app.post("/get_data")
async def stream_response(
    userprompt: str = Query(...),
    user_id: str = Query("anonymous", alias="userId"),
    session_id: str = Query(DUMMY_SESSION_ID, alias="sessionId"),
):
    print(f"\n{'='*60}")
    print(f"üü° NEW REQUEST: {userprompt}")
    print(f"{'='*60}\n")

    async def event_generator():
        try:
            async for event in interact_with_server(userprompt, session_id, user_id):
                # event is a string from encoder.encode()
                if not event.endswith('\n'):
                    event = event + '\n'
                yield event
                await asyncio.sleep(0)
        except Exception as e:
            print(f"‚ùå Generator error: {e}")
            traceback.print_exc()

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Content-Type": "text/event-stream",
        },
    )

@app.get("/health")
async def health_check():
    """Health check endpoint that also tests MCP server connectivity."""
    try:
        # Test MCP connection using ping (like your test script)
        mcp_connected = await test_mcp_connection()
       
        client = await create_mcp_client()
        async with client:
            tools = await client.list_tools()
           
            return {
                "status": "healthy" if mcp_connected else "degraded",
                "mcp_server": "connected" if mcp_connected else "disconnected",
                "available_tools": len(tools),
                "tools": [t.name for t in tools],
                "authentication": "enabled" if MCP_BASE_URL == "http://127.0.0.1:8000" else "custom",
                "mcp_endpoints": {
                    "token_url": MCP_TOKEN_URL,
                    "server_url": MCP_SERVER_URL
                }
            }
    except Exception as e:
        return {
            "status": "degraded",
            "mcp_server": "disconnected",
            "error": str(e),
            "authentication": "failed"
        }
 
@app.get("/test-mcp")
async def test_mcp_endpoint():
    """Test endpoint that replicates your test script functionality."""
    try:
        print("üß™ Testing MCP connection like test script...")
       
        # Replicate your test script exactly
        token = await fetch_mcp_token()
        if not token:
            return {"status": "failed", "error": "Could not obtain token"}
       
        transport = StreamableHttpTransport(
            url=MCP_SERVER_URL,
            headers={"Authorization": f"Bearer {token}"}
        )
       
        async with Client(transport) as c:
            result = await c.call_tool("ping")
            return {
                "status": "success",
                "message": "MCP connection test successful",
                "server_response": result.data,
                "token_obtained": True,
                "endpoints": {
                    "token_url": MCP_TOKEN_URL,
                    "server_url": MCP_SERVER_URL
                }
            }
           
    except Exception as e:
        return {
            "status": "failed",
            "error": str(e),
            "token_obtained": token is not None if 'token' in locals() else False
        }
    
    
# testing delete session endpoint 24hrs
@app.delete("/session")
async def delete_session(userId: str = Query("anonymous"), sessionId: str = Query(DUMMY_SESSION_ID)):
    """
    Delete Redis history for given userId + sessionId.
    Returns 200 on success, 404 if key not found, 503 if Redis unavailable.
    """
    try:
        if not redis_client:
            logger.warning("delete_session: redis_client not available")
            return {"status": "failed", "error": "redis unavailable"}

        key = make_history_key(userId, sessionId)
        deleted = redis_client.delete(key)
        if deleted:
            logger.info("Deleted session history key=%s for user=%s", key, userId)
            return {"status": "success", "deleted_keys": deleted}
        else:
            logger.info("delete_session: key not found %s", key)
            return {"status": "not_found", "deleted_keys": 0}
    except Exception as e:
        logger.error("delete_session failed for user=%s session=%s: %s", userId, sessionId, e)
        return {"status": "failed", "error": str(e)}
 
@app.get("/")
async def root():
    return {"status": "ok", "message": "AG-UI FastAPI server is running with MCP authentication"}
 
if __name__ == "__main__":
    print("üöÄ FastAPI AG-UI server starting on http://127.0.0.1:8001")
    print("üîê Azure authentication integration enabled")
    print(f"üîó MCP Server: {MCP_BASE_URL}")
    print(f"üé´ Token URL: {MCP_TOKEN_URL}")
    print(f"üì° MCP URL: {MCP_SERVER_URL}")
    print("üí° TIP: Visit /test-mcp to test authentication like your test script")
    print("üì° Ready to receive requests...")
   
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=8001,
        log_level="info",
        access_log=True,
    )
